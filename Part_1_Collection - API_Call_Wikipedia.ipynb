{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRUD\n",
    "\n",
    "| | SQL | RESTful API |\n",
    "|:-:|:-:|:-:|\n",
    "| create | `INSERT` | `POST` |\n",
    "| read | `SELECT` | `GET` |\n",
    "| update | `UPDATE` | `PUT` |\n",
    "| delete | `DELETE` | `DELETE` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://interactive.blockdiag.com/image?compression=deflate&encoding=base64&src=eJxLyslPzk7JTExXqOZSUFAPcnV0UUgrys9VKM_MzixIBcqoK-jaKRSlFpfmlBSDmOqefsGuQSEKJfkKBfnFJelAKXVrrloAaBAXgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Setup\n",
    "\n",
    "As there are pages that could have many categories, we need an additional pages-categories table as a part of our schema. It's like a single author writing multiple books - something like the below:\n",
    "\n",
    "![](http://2.bp.blogspot.com/-XqXauv9hrQ4/U3RXOjaW8qI/AAAAAAAAIiw/X7Pd2C41cAU/s1600/DatabaseRelationships.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PostgreSQL Schema\n",
    "\n",
    "To follow that same structure, we will want the following three tables:\n",
    "\n",
    "    pages\n",
    "    ====\n",
    "    links\n",
    "    page_categories\n",
    "    pageid (primary key)\n",
    "    summary\n",
    "    title\n",
    "    url  \n",
    "|page_id | title |\n",
    "|:-:|:-:|\n",
    "| 1 | logistic regression |\n",
    "| 2 | perceptron | \n",
    "| 3 | random forest | \n",
    "\n",
    "    category_pages\n",
    "    ========\n",
    "    page_id (foreign key)\n",
    "    timestamp\n",
    "    title\n",
    "    type\n",
    "    category_id (foreign key)\n",
    "    category_name\n",
    "| category_id | category_name | page_id | title |\n",
    "|:-:|:-:|:-:|:-:|\n",
    "| 1 | machine learning | 1 | logistic_regression\n",
    "| 2 | linear models | 2 | perceptron\n",
    "| 3 | tree models | 3 | random forest\n",
    "\n",
    "    categories\n",
    "    ========\n",
    "    category_id (primary key)\n",
    "    category_name\n",
    "    category_summary\n",
    "    url\n",
    "| category_id | category_name |\n",
    "|:-:|:-:|\n",
    "| 1 | machine learning |\n",
    "| 2 | linear models |\n",
    "| 3 | tree models |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz\n",
      "Requirement already satisfied (use --upgrade to upgrade): beautifulsoup4 in /opt/conda/lib/python3.5/site-packages (from wikipedia)\n",
      "Requirement already satisfied (use --upgrade to upgrade): requests<3.0.0,>=2.0.0 in /opt/conda/lib/python3.5/site-packages (from wikipedia)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Running setup.py bdist_wheel for wikipedia ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/bf/87/25/df698dd7b66a42c1c5f3bd36f8155d4518d210f5e2c128b440\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n",
      "\u001b[33mYou are using pip version 8.1.2, however version 9.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import wikipedia\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Categories Table (didn't use this one)...\n",
    "\n",
    "I was able to get all the pages and categories for Machine Learning and Business Software with the code below. However, for the purposes of this project, I needed more pages that belonged to several other categories as we are wanting to eventually build out a model that will predict categories. So we need a large dataset of several categories to train the model on. So this code didn't end up working and needed to develop a recursive function in order to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml_pages = urllib.request.urlopen(\"https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts&list=categorymembers&titles=Main+Page&exintro=1&explaintext=1&cmtitle=Category%3AMachine_learning&cmprop=ids%7Ctitle%7Ctype%7Ctimestamp&cmlimit=max\")\n",
    "ml_str_response = ml_pages.read().decode('utf-8')\n",
    "ml_data = json.loads(ml_str_response)\n",
    "ml_cat_df = pd.DataFrame(ml_data['query']['categorymembers'])\n",
    "ml_cat_df['category_id'] = wikipedia.page('Category:Machine_learning').pageid\n",
    "ml_cat_df['category'] = 'Machine learning'\n",
    "ml_cat_df['category_summary'] = wikipedia.page('Category:Machine_learning').summary\n",
    "ml_cat_df['url'] = wikipedia.page('Category:Machine_learning').url\n",
    "\n",
    "bu_pages = urllib.request.urlopen(\"https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts&list=categorymembers&titles=Main+Page&exintro=1&explaintext=1&cmtitle=Category%3ABusiness+software&cmprop=ids%7Ctitle%7Ctype%7Ctimestamp&cmlimit=max\")\n",
    "bu_str_response = bu_pages.read().decode('utf-8')\n",
    "bu_data = json.loads(bu_str_response)\n",
    "bu_cat_df = pd.DataFrame(bu_data['query']['categorymembers'])\n",
    "bu_cat_df['category_id'] = wikipedia.page('Category:Business software').pageid\n",
    "bu_cat_df['category'] = 'Business software'\n",
    "bu_cat_df['category_summary'] = wikipedia.page('Category:Business software').summary\n",
    "bu_cat_df['url'] = wikipedia.page('Category:Business software').url\n",
    "\n",
    "categories_pages_df = pd.concat([ml_cat_df,bu_cat_df], axis=0, join='outer')\n",
    "\n",
    "categories_pages_df.reset_index\n",
    "categories_pages_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories_pages_df.reset_index(drop='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories_pages_df.to_csv('categories_pages_dont_use.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Categories Tables with Functions\n",
    "\n",
    "The functions below is what I used in order to generate the categories_pages table. The end product is a recursive function that gets the contents of the pages within a category.\n",
    "\n",
    "I ended up just using the \"summary\" from the wikipedia API for each page as it had enough textual content to work with. Wikipedia had an option to call for all the content of a page but it was way too much text and it would affect model performence later on. So decided to go with the \"summary\" as it still had a substantial amount of text that describes the topic of the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_category(category):\n",
    "    category = re.sub('\\s','+',category)\n",
    "    return category\n",
    "\n",
    "def generate_query(category):\n",
    "    query = \"\"\"\n",
    "            http://en.wikipedia.org/w/api.php?\n",
    "            action=query&\n",
    "            format=json&\n",
    "            prop=extracts&\n",
    "            list=categorymembers&\n",
    "            titles=Main+Page&\n",
    "            exintro=1&\n",
    "            explaintext=1&\n",
    "            cmtitle=Category%3A{}&\n",
    "            cmprop=ids%7Ctitle%7Ctype%7Ctimestamp&\n",
    "            cmlimit=max\n",
    "            \"\"\".format(generate_category(category))\n",
    "    query = re.sub('\\s','',query)\n",
    "    return query\n",
    "\n",
    "def execute_category_query(category):\n",
    "    r = requests.get(generate_query(category))\n",
    "    response = r.json()\n",
    "    return pd.DataFrame(response['query']['categorymembers'])\n",
    "\n",
    "def category_to_dataframe(category):\n",
    "    df = execute_category_query(category)\n",
    "    category_string = 'Category:{}'.format(category)\n",
    "    df['category_id'] = wikipedia.page(category_string).pageid\n",
    "    df['category'] = category_string\n",
    "    df['category_summary'] = wikipedia.page(category_string).summary\n",
    "    df['url'] = wikipedia.page(category_string).url\n",
    "    return df\n",
    "\n",
    "def remove_category(category):\n",
    "    category = re.sub('Category:','',category)\n",
    "    return category\n",
    "\n",
    "#categories_to_query = category_to_dataframe(category)[category_mask]['title'].apply(remove_category).tolist()\n",
    "\n",
    "def get_all_pages_rec(category):\n",
    "    category_df = category_to_dataframe(category)\n",
    "    pages_list = []\n",
    "    category_mask = category_df['title'].str.contains('Category:')\n",
    "    pages_df = category_df[~category_mask]\n",
    "    pages_list.append(pages_df)\n",
    "    categories = category_df[category_mask]['title'].str.replace('Category:','').tolist()\n",
    "    if len(categories) > 0:\n",
    "        for cat in categories:\n",
    "            try:\n",
    "                pages_list.append(get_all_pages_rec(cat))\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    pages_df = pd.concat(pages_list)\n",
    "    pages_df.reset_index()\n",
    "    return pages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "machine_learning_cat_df = get_all_pages_rec('Machine_learning')\n",
    "machine_learning_cat_df.drop_duplicates()\n",
    "machine_learning_cat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business_cat_df = get_all_pages_rec('Business software')\n",
    "business_cat_df.drop_duplicates()\n",
    "business_cat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories_df = pd.concat([machine_learning_cat_df,business_cat_df], axis=0, join='outer')\n",
    "categories_df.reset_index(drop='index',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories_df.to_csv('categories_extract.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category = categories_df[['category_id','category','category_summary','url']]\n",
    "category.drop_duplicates(inplace=True)\n",
    "category.to_csv('categories.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories_df.drop(['ns','category_summary','url'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories_df.to_csv('categories_pages.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Pages Table - with Wikipedia API\n",
    "\n",
    "To get all the contents of the pages, I used the python library for the Wikipedia API. After getting all the data that I need, I threw everything into a dataframe and saved it to CSV's to put into my postgres database. Because the loads were taking so long and internet connection was spotty, ended up breaking these out into batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_df = pd.read_csv('categories_extract.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pages_id_list_1 = cat_df['pageid'].iloc[0:1000].tolist()\n",
    "pages_id_list_2 = cat_df['pageid'].iloc[1000:2000].tolist()\n",
    "pages_id_list_3 = cat_df['pageid'].iloc[2000:3000].tolist()\n",
    "pages_id_list_4 = cat_df['pageid'].iloc[3000:4000].tolist()\n",
    "pages_id_list_5 = cat_df['pageid'].iloc[5000:6000].tolist()\n",
    "pages_id_list_6 = cat_df['pageid'].iloc[6000:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pages_query(p_id):\n",
    "    temp_dict = {}\n",
    "    request = wikipedia.page(pageid=p_id)\n",
    "    temp_dict['pageid'] = request.pageid\n",
    "    temp_dict['title'] = request.title\n",
    "    temp_dict['links'] = request.links\n",
    "    temp_dict['page_categories'] = request.categories\n",
    "#    temp_dict['revision_id'] = request.revision_id\n",
    "#    temp_dict['images'] = request.images\n",
    "#    temp_dict['content'] = request.content\n",
    "    temp_dict['summary'] = request.summary\n",
    "#    temp_dict['references'] = request.references\n",
    "#    temp_dict['parent_id'] = request.parent_id\n",
    "    temp_dict['url'] = request.url\n",
    "    return temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###1st list\n",
    "\n",
    "pages = []\n",
    "for s in pages_id_list_1:\n",
    "    try:\n",
    "        pages.append(pages_query(s))\n",
    "        print('adding page')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "pages_df_1 = pd.DataFrame(pages)\n",
    "pages_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pages_df_1.to_csv('pages_df_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###2nd list\n",
    "\n",
    "pages = []\n",
    "for s in pages_id_list_2:\n",
    "    try:\n",
    "        pages.append(pages_query(s))\n",
    "        print('adding page')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "pages_df_2 = pd.DataFrame(pages)\n",
    "pages_df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pages_df_2.to_csv('pages_df_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###3rd list\n",
    "\n",
    "pages = []\n",
    "for s in pages_id_list_3:\n",
    "    try:\n",
    "        pages.append(pages_query(s))\n",
    "        print('adding page')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "pages_df_3 = pd.DataFrame(pages)\n",
    "pages_df_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pages_df_3.to_csv('pages_df_3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###4th list\n",
    "\n",
    "pages = []\n",
    "for s in pages_id_list_4:\n",
    "    try:\n",
    "        pages.append(pages_query(s))\n",
    "        print('adding page')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "pages_df_4 = pd.DataFrame(pages)\n",
    "pages_df_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pages_df_4.to_csv('pages_df_4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###5th list\n",
    "\n",
    "pages = []\n",
    "for s in pages_id_list_5:\n",
    "    try:\n",
    "        pages.append(pages_query(s))\n",
    "        print('adding page')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "pages_df_5 = pd.DataFrame(pages)\n",
    "pages_df_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pages_df_5.to_csv('pages_df_5.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###6th list\n",
    "\n",
    "pages = []\n",
    "for s in pages_id_list_6:\n",
    "    try:\n",
    "        pages.append(pages_query(s))\n",
    "        print('adding page')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "pages_df_6 = pd.DataFrame(pages)\n",
    "pages_df_6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pages_df_6.to_csv('pages_df_6.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pages_df_1 = pd.read_csv('pages_df_1.csv')\n",
    "pages_df_2 = pd.read_csv('pages_df_2.csv')\n",
    "pages_df_3 = pd.read_csv('pages_df_3.csv')\n",
    "pages_df_4 = pd.read_csv('pages_df_4.csv')\n",
    "pages_df_5 = pd.read_csv('pages_df_5.csv')\n",
    "pages_df_6 = pd.read_csv('pages_df_6.csv')\n",
    "\n",
    "pages_df = pd.concat([pages_df_1,pages_df_2,pages_df_3,pages_df_4,pages_df_5,pages_df_6], axis=0, join='outer')\n",
    "pages_df.reset_index(drop='index',inplace=True)\n",
    "pages_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pages_df.to_csv('pages.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_df = pd.read_csv('categories_pages_extract.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying pages with API URL's (didn't use this method)..\n",
    "\n",
    "Rather than using the Wikipedia Python API, I tried gathering the data directly with a query from the API. However, this method was difficult because it was taking a very long time to load the pages and also, it wasn't getting loaded into the dataframe correctly. So decided to use the above method instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_category(category):\n",
    "    category = re.sub('\\s','+',category)\n",
    "    return category\n",
    "\n",
    "def generate_page_query(page_id):\n",
    "    query = \"\"\"\n",
    "            http://en.wikipedia.org/w/api.php?\n",
    "            action=query&\n",
    "            format=json&\n",
    "            prop=extracts%7Ccategories%7Cinfo%7Cimages%7Clinks%7Crevisions%7Ccategoryinfo&\n",
    "            list=&\n",
    "            pageids={}&\n",
    "            exlimit=20&\n",
    "            exintro=1&\n",
    "            explaintext=1&\n",
    "            exsectionformat=wiki&\n",
    "            inprop=url%7Cdisplaytitle\n",
    "            \"\"\".format(generate_category(page_id))\n",
    "    query = re.sub('\\s','',query)\n",
    "    return query\n",
    "\n",
    "def execute_page_query(page_id):\n",
    "    r = requests.get(generate_page_query(page_id))\n",
    "    response = r.json()\n",
    "    return pd.DataFrame.from_dict(response['query']['pages'], orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "execute_page_query('15702071')['extract'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pages_id_list = categories_df['pageid'].tolist()\n",
    "\n",
    "df = pd.DataFrame(execute_page_query('40973765').columns)\n",
    "for s in sample_list:\n",
    "    try:\n",
    "        df.append(execute_page_query('s'))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Pages Table - with API urls (didn't use this method)..\n",
    "\n",
    "Couldn't get this to work very well because wikipedia api limits url's to have only 50 page id's and of those 50, can get only 20 extracts of text at a time. So didn't think this was a very good solution so didn't go the route below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "api_links = [\n",
    "    'https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts%7Ccategories%7Cinfo%7Cimages%7Clinks%7Crevisions%7Ccategoryinfo&list=&pageids=48290454%7C19317802%7C51112472%7C12386904%7C49316492%7C787776%7C416612%7C5767980%7C34042707%7C28255458%7C54550729%7C847558%7C4118276%7C6968451%7C3118600%7C387537%7C9583985%7C2934910%7C28650287%7C22795783%7C17114678%7C8964665%7C39182554%7C53631046%7C44439173%7C1191936%7C50646178%7C205393%7C40678189%7C50211107%7C40973765%7C35867897%7C9732182%7C31877832%7C14003441%7C19463198%7C49242352%7C20890511%7C50773876%7C30511763%7C52642349%7C45049676%7C28801798%7C43808044%7C3771060%7C53198248%7C53587467%7C233488%7C49082762%7C43385931&exlimit=20&exintro=1&explaintext=1&exsectionformat=wiki&inprop=url%7Cdisplaytitle'\n",
    "    'https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts%7Ccategories%7Cinfo%7Cimages%7Clinks%7Crevisions%7Ccategoryinfo&list=&pageids=10747879%7C28037054%7C54033657%7C43688866%7C4144848%7C46798615%7C41370976%7C2090057%7C5721283%7C48987892%7C470314%7C22589574%7C53279262%7C33762888%7C41644056%7C42579971%7C173926%7C5008963%7C32402755%7C1041204%7C4375576%7C50336055%7C40254%7C1222578%7C313845%7C2085584%7C34061548%7C38870173%7C36126852%7C46207323%7C1299404%7C21638340%7C14923880%7C8416103%7C460689%7C43218024%7C48833041%7C12304987%7C52003586%7C1455062%7C13750669%7C213214%7C10747995%7C45390860%7C1331441%7C12155912%7C579867%7C1422176%7C41755648%7C43169442&exlimit=20&exintro=1&explaintext=1&exsectionformat=wiki&inprop=url%7Cdisplaytitle'\n",
    "    'https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts%7Ccategories%7Cinfo%7Cimages%7Clinks%7Crevisions%7Ccategoryinfo&list=&pageids=41200806%7C24825162%7C9731945%7C21985449%7C6881120%7C34072838%7C11360852%7C2291650%7C126706%7C40946774%7C23864280%7C173332%7C42129549%7C10748030%7C44577560%7C19208664%7C7309022%7C45627703%7C48976249%7C18475546%7C52242050%7C14082194%7C48841414%7C30909817%7C30928751%7C938663%7C2854828%7C49786340%7C33998310%7C871681%7C4615464%7C12306500%7C44628821%7C47937215%7C53049812%7C48777199%7C53970843%7C53802271%7C5721403%7C45378845%7C44632031%7C53047074%7C46963137%7C523173%7C35272263%7C33890474%7C23864530%7C25050663%7C3274742%7C48827727&exlimit=20&exintro=1&explaintext=1&exsectionformat=wiki&inprop=url%7Cdisplaytitle'\n",
    "    'https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts%7Ccategories%7Cinfo%7Cimages%7Clinks%7Crevisions%7Ccategoryinfo&list=&pageids=42936114%7C33547387%7C47527969%7C52992310%7C7578809%7C43502368%7C39945557%7C47228422%7C233497%7C37787103%7C22999791%7C19058043%7C5077439%7C47577902%7C3920550%7C960361%7C50828755%7C1514392%7C20926%7C3119546%7C48844125%7C10704974%7C47845063%7C19667111%7C1053303%7C1579244%7C33886025%7C50227596%7C48813654%7C405562%7C47509138%7C38059657%7C29288159%7C2829632%7C50222574%7C14271782%7C995455%7C43269516%7C7517319%7C3290880%7C38782554%7C54625345%7C35887507%7C926722%7C43932548%7C37697003%7C14529261%7C41929726%7C44108758%7C41732818&exlimit=20&exintro=1&explaintext=1&exsectionformat=wiki&inprop=url%7Cdisplaytitle'\n",
    "    'https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts%7Ccategories%7Cinfo%7Cimages%7Clinks%7Crevisions%7Ccategoryinfo&list=&pageids=34845963%7C32797209%7C25957629%7C41672405%7C53108275%7C11971726%7C522230%7C38722262%7C34026570%7C53113973%7C19657756%7C35959361%7C22847264%7C1762176%7C54594603%7C24061342%7C12715119%7C44133735%7C28502793%7C5211212%7C41270069%7C1037763%7C52763828%7C31176997%7C52763867%7C40149461%7C11737376%7C52763829%7C3832584%7C24059390%7C47991509%7C44943481%7C33547228%7C28004586%7C36407925%7C19314112%7C20924581%7C12535256%7C29003796%7C3061615%7C754055%7C3985352%7C29549713%7C42320378%7C33542714%7C12932492%7C34310097%7C22532673%7C1991254%7C1718975&exlimit=20&exintro=1&explaintext=1&exsectionformat=wiki&inprop=url%7Cdisplaytitle'\n",
    "    'https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts%7Ccategories%7Cinfo%7Cimages%7Clinks%7Crevisions%7Ccategoryinfo&list=&pageids=17106978%7C1660841%7C26480448%7C16342561%7C34900000%7C40502799%7C9133131%7C24093035%7C469578%7C5988487%7C30429756%7C27208838%7C32958985%7C43689922%7C32244195%7C4166591%7C50994297%7C36808856%7C8385046%7C39219632%7C36862865%7C49791445%7C48824910%7C33085387%7C1733999%7C2528278%7C1155952%7C42005%7C32421587%7C43673868%7C22832929%7C50421011%7C26137900%7C24104531%7C48234685%7C41053071%7C32613108%7C40158733%7C53640074%7C7106579%7C18841448%7C4032051%7C1631564%7C3543438%7C27954944%7C3927666%7C54133478%7C38935938%7C2093407%7C33065316&exlimit=20&exintro=1&explaintext=1&exsectionformat=wiki&inprop=url%7Cdisplaytitle'\n",
    "    'https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts%7Ccategories%7Cinfo%7Cimages%7Clinks%7Crevisions%7Ccategoryinfo&list=&pageids=31975428%7C6987871%7C42363103%7C22230795%7C3691948%7C1174674%7C15516115%7C13443187%7C20391794%7C41669016%7C39946273%7C8522483%7C27976545%7C3070013%7C18487118%7C8083806%7C41667831%7C40693259%7C8343747%7C11028436%7C54135637%7C31954624%7C28544576%7C20414115%7C52641508%7C786016%7C28370294%7C18515583%7C34293559%7C49107824%7C2302514%7C47967038%7C12640130%7C24310774%7C52993539%7C2286665%7C904795%7C9597318%7C22807593%7C6603087%7C34208511%7C7674023%7C12840831%7C6456883%7C16144050%7C49680032%7C8648665%7C24747714%7C30522786%7C3445672&exlimit=20&exintro=1&explaintext=1&exsectionformat=wiki&inprop=url%7Cdisplaytitle'\n",
    "    'https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts%7Ccategories%7Cinfo%7Cimages%7Clinks%7Crevisions%7Ccategoryinfo&list=&pageids=39238529%7C25822348%7C54083259%7C2672138%7C2988291%7C22162830%7C40863938%7C1950870%7C1758239%7C23062020%7C237494%7C13452317%7C2370618%7C51412587%7C24200863%7C1743401%7C18096221%7C4996092%7C12185719%7C16567431%7C39244415%7C3139122%7C2029470%7C53969134%7C50313336%7C40312213%7C19885252%7C2011728%7C9611373%7C42812494%7C3620743%7C34025898%7C3568755%7C2361538%7C36488797%7C8793238%7C6093560%7C48231694%7C2901621%7C8148765%7C41261061%7C30708494%7C30703633%7C30727442%7C4175227%7C1971849%7C48547307%7C13224058%7C24766750%7C54205765&exlimit=20&exintro=1&explaintext=1&exsectionformat=wiki&inprop=url%7Cdisplaytitle'\n",
    "    'https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts%7Ccategories%7Cinfo%7Cimages%7Clinks%7Crevisions%7Ccategoryinfo&list=&pageids=47642826%7C27165706%7C32768675%7C49677616%7C2585120%7C46753689%7C22602354%7C17989579%7C17916442%7C23232660%7C51783746%7C41399235%7C34045703%7C44504550%7C36731269%7C33242335%7C40252780%7C7686145%7C29345392%7C15628716%7C638133%7C42113520%7C5588452%7C19029406%7C15465111%7C13264388%7C220633%7C40928146%7C30864276%7C25114536%7C6903579%7C3069932%7C52048578%7C28192984%7C1699107%7C45075900%7C26703974%7C52529493%7C9409598%7C53815511%7C47305095%7C5851855%7C3849008%7C41653781%7C27656596%7C41102584%7C41352219%7C31897073%7C28836625%7C50498591&exlimit=20&exintro=1&explaintext=1&exsectionformat=wiki&inprop=url%7Cdisplaytitle'\n",
    "    'https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts%7Ccategories%7Cinfo%7Cimages%7Clinks%7Crevisions%7Ccategoryinfo&list=&pageids=11154407%7C1290733%7C28096875%7C19925726%7C49258658%7C30518856%7C30821028%7C41533727%7C34027125%7C50644682%7C19140610%7C49478757%7C33761479%7C2399787%7C4175276%7C49521169%7C38109156%7C7364194%7C34793528%7C5845752%7C206586%7C2756846%7C30890479%7C42865956%7C19547325%7C24363618%7C30233970%7C40402832%7C28847674%7C26480028%7C33439781%7C3765816%7C32845520%7C6163915%7C25279503%7C31800111%7C22350998%7C12941228%7C25296555%7C2269864%7C43024112%7C49788699%7C30797416%7C35252701%7C37789882%7C22038673%7C28005288%7C39853660%7C47113160%7C19674177&exlimit=20&exintro=1&explaintext=1&exsectionformat=wiki&inprop=url%7Cdisplaytitle'\n",
    "    'https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts%7Ccategories%7Cinfo%7Cimages%7Clinks%7Crevisions%7Ccategoryinfo&list=&pageids=29576811%7C1706137%7C30220188%7C21137368%7C34292819%7C38739665%7C27490351%7C30303453%7C3813661%7C23785395%7C21283046%7C3964070%7C6702491%7C8733307%7C2504415%7C45686490%7C24925014%7C15459030%7C41517953%7C41517954%7C37041135%7C14541812%7C17799618%7C20727104%7C34061482%7C33185688%7C33906593%7C3234557%7C39214950%7C1693503%7C14568189%7C9466979%7C51957134%7C50515193%7C2840555%7C25745688%7C14546175%7C51567252%7C40453325%7C36292664%7C15095926%7C1745691%7C53984403%7C40727883%7C24272165%7C42460055%7C11648918%7C35152919%7C35127328%7C15309361&exlimit=20&exintro=1&explaintext=1&exsectionformat=wiki&inprop=url%7Cdisplaytitle'\n",
    "    'https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts%7Ccategories%7Cinfo%7Cimages%7Clinks%7Crevisions%7Ccategoryinfo&list=&pageids=9622164%7C23739219%7C9186941%7C53417207%7C26651713%7C38798197%7C9761144%7C2543335&exlimit=20&exintro=1&explaintext=1&exsectionformat=wiki&inprop=url%7Cdisplaytitle'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pages = {}\n",
    "for link in api_links:\n",
    "    page = urllib.request.urlopen(link)\n",
    "    str_response = page.read().decode('utf-8')\n",
    "    data = json.loads(str_response)\n",
    "    query = data['query']\n",
    "    pages.update(query)\n",
    "    \n",
    "    \n",
    "    pages_1 = urllib.request.urlopen(\"https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts%7Ccategories%7Cinfo%7Cimages%7Clinks%7Crevisions%7Ccategoryinfo&list=&pageids=48290454%7C19317802%7C51112472%7C12386904%7C49316492%7C787776%7C416612%7C5767980%7C34042707%7C28255458%7C54550729%7C847558%7C4118276%7C6968451%7C3118600%7C387537%7C9583985%7C2934910%7C28650287%7C22795783%7C17114678%7C8964665%7C39182554%7C53631046%7C44439173%7C1191936%7C50646178%7C205393%7C40678189%7C50211107%7C40973765%7C35867897%7C9732182%7C31877832%7C14003441%7C19463198%7C49242352%7C20890511%7C50773876%7C30511763%7C52642349%7C45049676%7C28801798%7C43808044%7C3771060%7C53198248%7C53587467%7C233488%7C49082762%7C43385931&exlimit=20&exintro=1&explaintext=1&exsectionformat=wiki&inprop=url%7Cdisplaytitle\")\n",
    "str_response_1 = pages_1.read().decode('utf-8')\n",
    "data_1 = json.loads(str_response_1)\n",
    "query_1 = data_1['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pages_1 = urllib.request.urlopen(\"https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts%7Ccategories%7Cinfo%7Cimages%7Clinks%7Crevisions%7Ccategoryinfo&list=&pageids=48290454%7C19317802%7C51112472%7C12386904%7C49316492%7C787776%7C416612%7C5767980%7C34042707%7C28255458%7C54550729%7C847558%7C4118276%7C6968451%7C3118600%7C387537%7C9583985%7C2934910%7C28650287%7C22795783%7C17114678%7C8964665%7C39182554%7C53631046%7C44439173%7C1191936%7C50646178%7C205393%7C40678189%7C50211107%7C40973765%7C35867897%7C9732182%7C31877832%7C14003441%7C19463198%7C49242352%7C20890511%7C50773876%7C30511763%7C52642349%7C45049676%7C28801798%7C43808044%7C3771060%7C53198248%7C53587467%7C233488%7C49082762%7C43385931&exlimit=20&exintro=1&explaintext=1&exsectionformat=wiki&inprop=url%7Cdisplaytitle\")\n",
    "str_response_1 = pages_1.read().decode('utf-8')\n",
    "data_1 = json.loads(str_response_1)\n",
    "query_1 = data_1['query']\n",
    "pages_1 = pd.DataFrame(query_1['pages']).T\n",
    "\n",
    "pages_2 = urllib.request.urlopen(\"https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts%7Ccategories%7Cinfo%7Cimages%7Clinks%7Crevisions%7Ccategoryinfo&list=&pageids=10747879%7C28037054%7C54033657%7C43688866%7C4144848%7C46798615%7C41370976%7C2090057%7C5721283%7C48987892%7C470314%7C22589574%7C53279262%7C33762888%7C41644056%7C42579971%7C173926%7C5008963%7C32402755%7C1041204%7C4375576%7C50336055%7C40254%7C1222578%7C313845%7C2085584%7C34061548%7C38870173%7C36126852%7C46207323%7C1299404%7C21638340%7C14923880%7C8416103%7C460689%7C43218024%7C48833041%7C12304987%7C52003586%7C1455062%7C13750669%7C213214%7C10747995%7C45390860%7C1331441%7C12155912%7C579867%7C1422176%7C41755648%7C43169442&exlimit=20&exintro=1&explaintext=1&exsectionformat=wiki&inprop=url%7Cdisplaytitle\")\n",
    "str_response_2 = pages_2.read().decode('utf-8')\n",
    "data_2 = json.loads(str_response_2)\n",
    "query_2 = data_2['query']\n",
    "pages_2 = pd.DataFrame(query_2['pages']).T\n",
    "\n",
    "pages_3 = urllib.request.urlopen(\"https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts%7Ccategories%7Cinfo%7Cimages%7Clinks%7Crevisions%7Ccategoryinfo&list=&pageids=41200806%7C24825162%7C9731945%7C21985449%7C6881120%7C34072838%7C11360852%7C2291650%7C126706%7C40946774%7C23864280%7C173332%7C42129549%7C10748030%7C44577560%7C19208664%7C7309022%7C45627703%7C48976249%7C18475546%7C52242050%7C14082194%7C48841414%7C30909817%7C30928751%7C938663%7C2854828%7C49786340%7C33998310%7C871681%7C4615464%7C12306500%7C44628821%7C47937215%7C53049812%7C48777199%7C53970843%7C53802271%7C5721403%7C45378845%7C44632031%7C53047074%7C46963137%7C523173%7C35272263%7C33890474%7C23864530%7C25050663%7C3274742%7C48827727&exlimit=20&exintro=1&explaintext=1&exsectionformat=wiki&inprop=url%7Cdisplaytitle\")\n",
    "str_response_3 = pages_3.read().decode('utf-8')\n",
    "data_3 = json.loads(str_response_3)\n",
    "query_3 = data_3['query']\n",
    "pages_3 = pd.DataFrame(query_3['pages']).T\n",
    "\n",
    "pages_4 = urllib.request.urlopen(\"https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts%7Ccategories%7Cinfo%7Cimages%7Clinks%7Crevisions%7Ccategoryinfo&list=&pageids=42936114%7C33547387%7C47527969%7C52992310%7C7578809%7C43502368%7C39945557%7C47228422%7C233497%7C37787103%7C22999791%7C19058043%7C5077439%7C47577902%7C3920550%7C960361%7C50828755%7C1514392%7C20926%7C3119546%7C48844125%7C10704974%7C47845063%7C19667111%7C1053303%7C1579244%7C33886025%7C50227596%7C48813654%7C405562%7C47509138%7C38059657%7C29288159%7C2829632%7C50222574%7C14271782%7C995455%7C43269516%7C7517319%7C3290880%7C38782554%7C54625345%7C35887507%7C926722%7C43932548%7C37697003%7C14529261%7C41929726%7C44108758%7C41732818&exlimit=20&exintro=1&explaintext=1&exsectionformat=wiki&inprop=url%7Cdisplaytitle\")\n",
    "str_response_4 = pages_4.read().decode('utf-8')\n",
    "data_4 = json.loads(str_response_4)\n",
    "query_4 = data_4['query']\n",
    "pages_4 = pd.DataFrame(query_4['pages']).T\n",
    "\n",
    "pages_5 = urllib.request.urlopen(\"https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts%7Ccategories%7Cinfo%7Cimages%7Clinks%7Crevisions%7Ccategoryinfo&list=&pageids=34845963%7C32797209%7C25957629%7C41672405%7C53108275%7C11971726%7C522230%7C38722262%7C34026570%7C53113973%7C19657756%7C35959361%7C22847264%7C1762176%7C54594603%7C24061342%7C12715119%7C44133735%7C28502793%7C5211212%7C41270069%7C1037763%7C52763828%7C31176997%7C52763867%7C40149461%7C11737376%7C52763829%7C3832584%7C24059390%7C47991509%7C44943481%7C33547228%7C28004586%7C36407925%7C19314112%7C20924581%7C12535256%7C29003796%7C3061615%7C754055%7C3985352%7C29549713%7C42320378%7C33542714%7C12932492%7C34310097%7C22532673%7C1991254%7C1718975&exlimit=20&exintro=1&explaintext=1&exsectionformat=wiki&inprop=url%7Cdisplaytitle\")\n",
    "str_response_5 = pages_5.read().decode('utf-8')\n",
    "data_5 = json.loads(str_response_5)\n",
    "query_5 = data_5['query']\n",
    "pages_5 = pd.DataFrame(query_5['pages']).T\n",
    "\n",
    "pages_6 = urllib.request.urlopen(\"https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts%7Ccategories%7Cinfo%7Cimages%7Clinks%7Crevisions%7Ccategoryinfo&list=&pageids=17106978%7C1660841%7C26480448%7C16342561%7C34900000%7C40502799%7C9133131%7C24093035%7C469578%7C5988487%7C30429756%7C27208838%7C32958985%7C43689922%7C32244195%7C4166591%7C50994297%7C36808856%7C8385046%7C39219632%7C36862865%7C49791445%7C48824910%7C33085387%7C1733999%7C2528278%7C1155952%7C42005%7C32421587%7C43673868%7C22832929%7C50421011%7C26137900%7C24104531%7C48234685%7C41053071%7C32613108%7C40158733%7C53640074%7C7106579%7C18841448%7C4032051%7C1631564%7C3543438%7C27954944%7C3927666%7C54133478%7C38935938%7C2093407%7C33065316&exlimit=20&exintro=1&explaintext=1&exsectionformat=wiki&inprop=url%7Cdisplaytitle\")\n",
    "str_response_6 = pages_6.read().decode('utf-8')\n",
    "data_6 = json.loads(str_response_6)\n",
    "query_6 = data_6['query']\n",
    "pages_6 = pd.DataFrame(query_6['pages']).T\n",
    "\n",
    "pages_7 = urllib.request.urlopen(\"https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts%7Ccategories%7Cinfo%7Cimages%7Clinks%7Crevisions%7Ccategoryinfo&list=&pageids=31975428%7C6987871%7C42363103%7C22230795%7C3691948%7C1174674%7C15516115%7C13443187%7C20391794%7C41669016%7C39946273%7C8522483%7C27976545%7C3070013%7C18487118%7C8083806%7C41667831%7C40693259%7C8343747%7C11028436%7C54135637%7C31954624%7C28544576%7C20414115%7C52641508%7C786016%7C28370294%7C18515583%7C34293559%7C49107824%7C2302514%7C47967038%7C12640130%7C24310774%7C52993539%7C2286665%7C904795%7C9597318%7C22807593%7C6603087%7C34208511%7C7674023%7C12840831%7C6456883%7C16144050%7C49680032%7C8648665%7C24747714%7C30522786%7C3445672&exlimit=20&exintro=1&explaintext=1&exsectionformat=wiki&inprop=url%7Cdisplaytitle\")\n",
    "str_response_7 = pages_7.read().decode('utf-8')\n",
    "data_7 = json.loads(str_response_7)\n",
    "query_7 = data_7['query']\n",
    "pages_7 = pd.DataFrame(query_7['pages']).T\n",
    "\n",
    "pages_8 = urllib.request.urlopen(\"https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts%7Ccategories%7Cinfo%7Cimages%7Clinks%7Crevisions%7Ccategoryinfo&list=&pageids=39238529%7C25822348%7C54083259%7C2672138%7C2988291%7C22162830%7C40863938%7C1950870%7C1758239%7C23062020%7C237494%7C13452317%7C2370618%7C51412587%7C24200863%7C1743401%7C18096221%7C4996092%7C12185719%7C16567431%7C39244415%7C3139122%7C2029470%7C53969134%7C50313336%7C40312213%7C19885252%7C2011728%7C9611373%7C42812494%7C3620743%7C34025898%7C3568755%7C2361538%7C36488797%7C8793238%7C6093560%7C48231694%7C2901621%7C8148765%7C41261061%7C30708494%7C30703633%7C30727442%7C4175227%7C1971849%7C48547307%7C13224058%7C24766750%7C54205765&exlimit=20&exintro=1&explaintext=1&exsectionformat=wiki&inprop=url%7Cdisplaytitle\")\n",
    "str_response_8 = pages_8.read().decode('utf-8')\n",
    "data_8 = json.loads(str_response_8)\n",
    "query_8 = data_8['query']\n",
    "pages_8 = pd.DataFrame(query_8['pages']).T\n",
    "\n",
    "pages_9 = urllib.request.urlopen(\"https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts%7Ccategories%7Cinfo%7Cimages%7Clinks%7Crevisions%7Ccategoryinfo&list=&pageids=47642826%7C27165706%7C32768675%7C49677616%7C2585120%7C46753689%7C22602354%7C17989579%7C17916442%7C23232660%7C51783746%7C41399235%7C34045703%7C44504550%7C36731269%7C33242335%7C40252780%7C7686145%7C29345392%7C15628716%7C638133%7C42113520%7C5588452%7C19029406%7C15465111%7C13264388%7C220633%7C40928146%7C30864276%7C25114536%7C6903579%7C3069932%7C52048578%7C28192984%7C1699107%7C45075900%7C26703974%7C52529493%7C9409598%7C53815511%7C47305095%7C5851855%7C3849008%7C41653781%7C27656596%7C41102584%7C41352219%7C31897073%7C28836625%7C50498591&exlimit=20&exintro=1&explaintext=1&exsectionformat=wiki&inprop=url%7Cdisplaytitle\")\n",
    "str_response_9 = pages_9.read().decode('utf-8')\n",
    "data_9 = json.loads(str_response_9)\n",
    "query_9 = data_9['query']\n",
    "pages_9 = pd.DataFrame(query_9['pages']).T\n",
    "\n",
    "pages_10 = urllib.request.urlopen(\"https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts%7Ccategories%7Cinfo%7Cimages%7Clinks%7Crevisions%7Ccategoryinfo&list=&pageids=11154407%7C1290733%7C28096875%7C19925726%7C49258658%7C30518856%7C30821028%7C41533727%7C34027125%7C50644682%7C19140610%7C49478757%7C33761479%7C2399787%7C4175276%7C49521169%7C38109156%7C7364194%7C34793528%7C5845752%7C206586%7C2756846%7C30890479%7C42865956%7C19547325%7C24363618%7C30233970%7C40402832%7C28847674%7C26480028%7C33439781%7C3765816%7C32845520%7C6163915%7C25279503%7C31800111%7C22350998%7C12941228%7C25296555%7C2269864%7C43024112%7C49788699%7C30797416%7C35252701%7C37789882%7C22038673%7C28005288%7C39853660%7C47113160%7C19674177&exlimit=20&exintro=1&explaintext=1&exsectionformat=wiki&inprop=url%7Cdisplaytitle\")\n",
    "str_response_10 = pages_10.read().decode('utf-8')\n",
    "data_10 = json.loads(str_response_10)\n",
    "query_10 = data_10['query']\n",
    "pages_10 = pd.DataFrame(query_10['pages']).T\n",
    "\n",
    "pages_11 = urllib.request.urlopen(\"https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts%7Ccategories%7Cinfo%7Cimages%7Clinks%7Crevisions%7Ccategoryinfo&list=&pageids=29576811%7C1706137%7C30220188%7C21137368%7C34292819%7C38739665%7C27490351%7C30303453%7C3813661%7C23785395%7C21283046%7C3964070%7C6702491%7C8733307%7C2504415%7C45686490%7C24925014%7C15459030%7C41517953%7C41517954%7C37041135%7C14541812%7C17799618%7C20727104%7C34061482%7C33185688%7C33906593%7C3234557%7C39214950%7C1693503%7C14568189%7C9466979%7C51957134%7C50515193%7C2840555%7C25745688%7C14546175%7C51567252%7C40453325%7C36292664%7C15095926%7C1745691%7C53984403%7C40727883%7C24272165%7C42460055%7C11648918%7C35152919%7C35127328%7C15309361&exlimit=20&exintro=1&explaintext=1&exsectionformat=wiki&inprop=url%7Cdisplaytitle\")\n",
    "str_response_11 = pages_11.read().decode('utf-8')\n",
    "data_11 = json.loads(str_response_11)\n",
    "query_11 = data_11['query']\n",
    "pages_11 = pd.DataFrame(query_11['pages']).T\n",
    "\n",
    "pages_12 = urllib.request.urlopen(\"https://en.wikipedia.org/w/api.php?action=query&format=json&prop=extracts%7Ccategories%7Cinfo%7Cimages%7Clinks%7Crevisions%7Ccategoryinfo&list=&pageids=9622164%7C23739219%7C9186941%7C53417207%7C26651713%7C38798197%7C9761144%7C2543335&exlimit=20&exintro=1&explaintext=1&exsectionformat=wiki&inprop=url%7Cdisplaytitle\")\n",
    "str_response_12 = pages_12.read().decode('utf-8')\n",
    "data_12 = json.loads(str_response_4)\n",
    "query_12 = data_12['query']\n",
    "pages_12 = pd.DataFrame(query_12['pages']).T\n",
    "\n",
    "pages_df = pd.concat([pages_1,pages_2,pages_3,pages_4,pages_5,pages_6,pages_7,pages_8,pages_9,pages_10,pages_11,pages_12], axis=0, join='outer')\n",
    "pages_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d1df = pd.DataFrame.from_dict(data_1['query']['pages'], orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d1df.categories.values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
